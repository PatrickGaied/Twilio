{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Brand Ads OCR — DeepSeek‑OCR \n",
        "\n",
        "This notebook fetches ad images (Apple, Samsung, Huawei, Yamaha), runs **DeepSeek‑OCR** via the official Hugging Face Transformers path, and produces a table with predicted **brand** and a short **entity** blurb.\n",
        "\n",
        "**References:** Model card & repo usage for DeepSeek‑OCR (tested env + API).\n",
        "\n",
        "- Hugging Face model: `deepseek-ai/DeepSeek-OCR`  \n",
        "- GitHub README (**Transformers-Inference** section): uses `AutoTokenizer/AutoModel(..., trust_remote_code=True)` and `model.infer(...)` with prompts like `\"<image>\\nFree OCR.\"`.\n",
        "\n",
        "> GPU strongly recommended (CUDA 11.8). CPU may be slow/unsupported.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Install (run on your machine / Colab)\n",
        "Pinned versions per model card/README. Adjust CUDA wheel if needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Setup: paths & helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, re, io, csv, time, json, glob, pathlib\n",
        "from typing import Optional\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "\n",
        "ROOT = pathlib.Path('.')\n",
        "DATA = ROOT / 'data'\n",
        "IMAGES = DATA / 'images'\n",
        "OUT = DATA / 'outputs'\n",
        "OCR_JSON = OUT / 'ocr_json'\n",
        "for p in [DATA, IMAGES, OUT, OCR_JSON]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def slug(s: str) -> str:\n",
        "    return re.sub(r'[^a-zA-Z0-9]+', '_', s).strip('_')\n",
        "\n",
        "def og_image(page_url: str) -> Optional[str]:\n",
        "    try:\n",
        "        html = requests.get(page_url, timeout=20).text\n",
        "        soup = BeautifulSoup(html, 'html.parser')\n",
        "        tag = soup.find('meta', property='og:image')\n",
        "        if tag and tag.get('content'):\n",
        "            return tag['content']\n",
        "    except Exception as e:\n",
        "        print('OG image error:', page_url, e)\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Manifest "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "manifest_path = DATA / 'manifest.csv'\n",
        "if not manifest_path.exists():\n",
        "    rows = [\n",
        "        # Apple (5)\n",
        "        {\"brand\":\"Apple\",\"title\":\"Come Rain or Come Shine\",\"medium\":\"Film\",\"year\":\"\",\"region\":\"\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/come-rain-or-come-shine\"},\n",
        "        {\"brand\":\"Apple\",\"title\":\"Shot on iPhone\",\"medium\":\"OOH/Print/Film\",\"year\":\"2019\",\"region\":\"US\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/shot-on-iphone\"},\n",
        "        {\"brand\":\"Apple\",\"title\":\"Your next computer is not a computer\",\"medium\":\"Film/Digital\",\"year\":\"2021\",\"region\":\"US\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/your-next-computer-is-not-a-computer\"},\n",
        "        {\"brand\":\"Apple\",\"title\":\"Mac goes to College\",\"medium\":\"Film/Digital\",\"year\":\"2025\",\"region\":\"US\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/mac-goes-to-college\"},\n",
        "        {\"brand\":\"Apple\",\"title\":\"Dear Apple\",\"medium\":\"Film/Digital\",\"year\":\"2022\",\"region\":\"US\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/dear-apple\"},\n",
        "        # Samsung (5)\n",
        "        {\"brand\":\"Samsung\",\"title\":\"The Real Upgrade\",\"medium\":\"Film/Digital\",\"year\":\"\",\"region\":\"\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/the-real-upgrade\"},\n",
        "        {\"brand\":\"Samsung\",\"title\":\"No reflections\",\"medium\":\"Print\",\"year\":\"2020\",\"region\":\"Germany\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/no-reflections\"},\n",
        "        {\"brand\":\"Samsung\",\"title\":\"Experience the wonder with the Galaxy\",\"medium\":\"Film/Digital\",\"year\":\"2021\",\"region\":\"Mongolia\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/experience-the-wonder-with-the-galaxy\"},\n",
        "        {\"brand\":\"Samsung\",\"title\":\"Big News\",\"medium\":\"Film/Digital\",\"year\":\"2023\",\"region\":\"Sweden\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/big-news\"},\n",
        "        {\"brand\":\"Samsung\",\"title\":\"For life with you\",\"medium\":\"Film/Digital\",\"year\":\"2025\",\"region\":\"Brazil\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/for-the-life-with-you\"},\n",
        "        # Huawei (5)\n",
        "        {\"brand\":\"Huawei\",\"title\":\"World, Unfolded.\",\"medium\":\"Film\",\"year\":\"2025\",\"region\":\"\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/huawei-world-unfolded\"},\n",
        "        {\"brand\":\"Huawei\",\"title\":\"Giant Smart\",\"medium\":\"Print/OOH\",\"year\":\"2025\",\"region\":\"AU/BR/FR\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/huawei-giant-smart\"},\n",
        "        {\"brand\":\"Huawei\",\"title\":\"Welcome to the Huawei AppGallery\",\"medium\":\"Digital/Film\",\"year\":\"2020\",\"region\":\"Israel\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/welcome-to-the-huawei-appgallery\"},\n",
        "        {\"brand\":\"Huawei\",\"title\":\"The Unofficial Smartphone\",\"medium\":\"Film/Digital\",\"year\":\"2018\",\"region\":\"Mexico\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/the-unofficial-smartphone\"},\n",
        "        {\"brand\":\"Huawei\",\"title\":\"Inspiration In Bloom\",\"medium\":\"OOH/Print\",\"year\":\"2025\",\"region\":\"BR/FR/UK\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/huawei-inspiration-in-bloom\"},\n",
        "        # Yamaha (5)\n",
        "        {\"brand\":\"Yamaha\",\"title\":\"Reveal\",\"medium\":\"Print/OOH\",\"year\":\"2014\",\"region\":\"Italy\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/reveal\"},\n",
        "        {\"brand\":\"Yamaha\",\"title\":\"Off-ROAD MILKSHAKE\",\"medium\":\"Activation/Film\",\"year\":\"2025\",\"region\":\"\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/off-road-milkshake\"},\n",
        "        {\"brand\":\"Yamaha\",\"title\":\"Neurons\",\"medium\":\"Print\",\"year\":\"2017\",\"region\":\"Italy\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/neurons\"},\n",
        "        {\"brand\":\"Yamaha\",\"title\":\"Balls\",\"medium\":\"Print\",\"year\":\"2016\",\"region\":\"Israel\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/balls-74ffa437-ae4d-4cd2-b8e7-b8d6596db2e4\"},\n",
        "        {\"brand\":\"Yamaha\",\"title\":\"Paper City\",\"medium\":\"Print\",\"year\":\"2011\",\"region\":\"Italy\",\"page_url\":\"https://www.adsoftheworld.com/campaigns/paper-city-31cdab6b-2bea-4394-be46-0dd3ffcba459\"}\n",
        "    ]\n",
        "    pd.DataFrame(rows).to_csv(manifest_path, index=False)\n",
        "manifest_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Fetch hero images via `og:image`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(manifest_path)\n",
        "downloaded = []\n",
        "for i, row in df.iterrows():\n",
        "    img_url = og_image(row['page_url'])\n",
        "    if not img_url:\n",
        "        print('No image', row['page_url'])\n",
        "        continue\n",
        "    name = f\"{row['brand']}_{slug(row['title'])}.jpg\"\n",
        "    path = IMAGES / name\n",
        "    if path.exists():\n",
        "        downloaded.append(str(path))\n",
        "        continue\n",
        "    try:\n",
        "        r = requests.get(img_url, timeout=30)\n",
        "        r.raise_for_status()\n",
        "        open(path, 'wb').write(r.content)\n",
        "        downloaded.append(str(path))\n",
        "        time.sleep(0.7)\n",
        "    except Exception as e:\n",
        "        print('Download error', img_url, e)\n",
        "len(downloaded), downloaded[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) DeepSeek‑OCR \n",
        "We use the **official pattern**: `AutoTokenizer/AutoModel(..., trust_remote_code=True)` and `model.infer(...)` with a plain OCR prompt. See model card/README for the exact versions and examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from PIL import Image\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_name = 'deepseek-ai/DeepSeek-OCR'\n",
        "\n",
        "# trust_remote_code is required; model exposes a custom `.infer(...)` helper\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModel.from_pretrained(\n",
        "    model_name,\n",
        "    _attn_implementation='flash_attention_2',\n",
        "    trust_remote_code=True,\n",
        "    use_safetensors=True\n",
        ")\n",
        "model = model.eval()\n",
        "if device == 'cuda':\n",
        "    model = model.to(torch.bfloat16).cuda()\n",
        "\n",
        "# Prompts per README examples; plain OCR works well for ads/key visuals\n",
        "OCR_PROMPT = \"<image>\\nFree OCR.\"\n",
        "# Alternative with layout grounding (often great for posters/PDFs):\n",
        "# OCR_PROMPT = \"<image>\\n<|grounding|>Convert the document to markdown.\"\n",
        "\n",
        "def deepseek_ocr_image(image_path: str) -> str:\n",
        "    # Official helper function exposed via trust_remote_code — returns text\n",
        "    res = model.infer(\n",
        "        tokenizer,\n",
        "        prompt=OCR_PROMPT,\n",
        "        image_file=image_path,\n",
        "        output_path=str(OUT),\n",
        "        base_size=1024,\n",
        "        image_size=640,\n",
        "        crop_mode=True,\n",
        "        save_results=False,\n",
        "        test_compress=True\n",
        "    )\n",
        "    # Some builds return a dict; others return a string — normalize\n",
        "    if isinstance(res, dict):\n",
        "        return res.get('text', '') or res.get('output', '') or ''\n",
        "    return str(res) if res is not None else ''\n",
        "\n",
        "print('DeepSeek‑OCR loaded on', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Brand rules & entity heuristic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "CANON = [\"apple\",\"samsung\",\"huawei\",\"yamaha\"]\n",
        "ALIASES = {\n",
        "    \"apple\":   [r\"\\biphone\\b\", r\"\\bipad\\b\", r\"\\bmac\\b\", r\"\\bapple watch\\b\", r\"\\bairpods\\b\", r\"\\bapple\\b\"],\n",
        "    \"samsung\": [r\"\\bgalaxy\\b\", r\"\\bsamsung\\b\", r\"\\bz flip\\b\", r\"\\bs24\\b\", r\"\\bnote\\b\"],\n",
        "    \"huawei\":  [r\"\\bhuawei\\b\", r\"\\bmate\\b\", r\"\\bpura\\b\", r\"\\bnova\\b\"],\n",
        "    \"yamaha\":  [r\"\\byamaha\\b\", r\"\\byzf\\b\", r\"\\bfz\\b\", r\"\\br1\\b\", r\"\\bmt-0?\\d\\b\", r\"\\brevstar\\b\", r\"\\bclavinova\\b\"],\n",
        "}\n",
        "BLACKLIST = set(CANON + [\"iphone\",\"ipad\",\"mac\",\"airpods\",\"watch\",\"galaxy\",\"mate\",\"pura\",\"nova\",\"yzf\",\"fz\",\"r1\"]) \n",
        "\n",
        "def detect_brand(ocr_text: str) -> str:\n",
        "    t = ocr_text.lower()\n",
        "    for brand, pats in ALIASES.items():\n",
        "        for p in pats:\n",
        "            if re.search(p, t):\n",
        "                return brand.capitalize()\n",
        "    return \"Unknown\"\n",
        "\n",
        "def short_entity(ocr_text: str, max_words: int = 6) -> str:\n",
        "    words = re.findall(r\"[a-zA-Z]+\", ocr_text.lower())\n",
        "    keep = [w for w in words if w not in BLACKLIST and 3 <= len(w) <= 12]\n",
        "    return \" \".join(keep[:max_words]) or \"generic scene\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Run OCR over images → JSON dumps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "records = []\n",
        "for img_path in sorted(IMAGES.glob('*.jpg')):\n",
        "    base = img_path.stem\n",
        "    out = OCR_JSON / f\"{base}.json\"\n",
        "    if out.exists():\n",
        "        rec = json.load(open(out))\n",
        "        records.append(rec)\n",
        "        continue\n",
        "    text = deepseek_ocr_image(str(img_path))\n",
        "    rec = {\"image\": base, \"text\": text}\n",
        "    json.dump(rec, open(out, 'w'))\n",
        "    records.append(rec)\n",
        "len(records), records[:2] if records else []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Predictions table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_rows = []\n",
        "for rec in records:\n",
        "    text = rec.get('text','')\n",
        "    pred_rows.append({\n",
        "        'image': rec['image'],\n",
        "        'brand_pred': detect_brand(text),\n",
        "        'entity': short_entity(text),\n",
        "        'ocr_text': text\n",
        "    })\n",
        "pred_df = pd.DataFrame(pred_rows)\n",
        "pred_csv = OUT / 'predictions.csv'\n",
        "pred_df.to_csv(pred_csv, index=False)\n",
        "pred_df.head(10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
